# app.py

import torch
import gradio as gr
from transformers import AutoTokenizer
from peft import AutoPeftModelForCausalLM

# === –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ —Å chat_template ===
model_path = "nikatonika/Llama-3.2-1B-Instruct_v1_ext_chat_template"

# === –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ ===
tokenizer = AutoTokenizer.from_pretrained(model_path)
tokenizer.pad_token = tokenizer.eos_token
tokenizer.padding_side = "right"

model = AutoPeftModelForCausalLM.from_pretrained(
    model_path,
    torch_dtype=torch.float16,
    device_map="auto"
)
model.eval()

# === –ì–µ–Ω–µ—Ä–∞—Ü–∏—è ===
def generate_response(user_input, max_new_tokens, temperature, top_p):
    prompt = f"""You are Dr. Gregory House, a world-class diagnostician known for sarcasm, wit, and medical expertise.
You don't sugarcoat anything and always rely on logic and medical facts.

Answer concisely, with dry humor and intelligence.

User: {user_input}
Dr. House:"""

    inputs = tokenizer(prompt.strip(), return_tensors="pt").to(model.device)

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=max_new_tokens,
            temperature=temperature,
            top_p=top_p,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id
        )

    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)
    response = decoded.split("Dr. House:")[-1].strip()

    if response.count(".") >= 2:
        response = ".".join(response.split(".")[:2]) + "."

    return response

# === Gradio-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å ===
with gr.Blocks() as demo:
    gr.Markdown("## üß† HouseMD Chatbot ‚Äî Llama-3.2-1B ChatTemplate")
    gr.Markdown("–î–æ–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å, –∏–º–∏—Ç–∏—Ä—É—é—â–∞—è —Å—Ç–∏–ª—å –¥–æ–∫—Ç–æ—Ä–∞ –•–∞—É—Å–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è `chat_template` –∏ —Ä—É—á–Ω–æ–π prompt.")

    with gr.Row():
        with gr.Column(scale=2):
            user_input = gr.Textbox(label="–í–æ–ø—Ä–æ—Å –ø–∞—Ü–∏–µ–Ω—Ç–∫–∏", placeholder="Why am I still sick?")
            max_tokens = gr.Slider(32, 200, value=80, step=8, label="–ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤")
            temperature = gr.Slider(0.1, 1.5, value=0.7, step=0.1, label="Temperature")
            top_p = gr.Slider(0.5, 1.0, value=0.9, step=0.05, label="Top-p")
            button = gr.Button("–°–ø—Ä–æ—Å–∏—Ç—å –¥–æ–∫—Ç–æ—Ä–∞ –•–∞—É—Å–∞")
        with gr.Column(scale=3):
            output = gr.Textbox(label="–û—Ç–≤–µ—Ç –•–∞—É—Å–∞", lines=4)

    button.click(fn=generate_response,
                 inputs=[user_input, max_tokens, temperature, top_p],
                 outputs=output)

if __name__ == "__main__":
    demo.launch()
